{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9528f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f8b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('ML_Data_48.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5e1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Z_jerk_mean', 'X_jerk_mean', 'total_jerk_mean', 'Y_jerk_mean','X_jerk_mean','X_jerk_min', 'X_min', 'timestamp_range'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4f6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6bf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['label'], axis=1)\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9484ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=StandardScaler()\n",
    "x=scale.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e292cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2614, 40), (1121, 40))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_t, y_train, y_t= train_test_split(x,y,test_size=0.3, random_state=42)\n",
    "x_train.shape, x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659799ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((952, 40), (169, 40))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, x_test, y_val, y_test= train_test_split(x_t, y_t, test_size=0.15, random_state=42)\n",
    "x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f47d9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 04:59:07.875005: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-28 04:59:07.893769: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-28 04:59:07.921125: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-28 04:59:07.921153: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-28 04:59:07.921170: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-28 04:59:07.925976: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-28 04:59:07.926669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-28 04:59:08.699672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d89b654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_heads, ff_dim, input_dim, dropout_rate, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=input_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(input_dim)  # Match the input dimension for residual connection\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.attention(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Build Transformer Model for Tabular Data\n",
    "def build_transformer_model(input_dim, output_dim, num_heads, ff_dim, num_transformer_blocks, dropout_rate):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    # Reshape to 3D for multi-head attention\n",
    "    x = layers.Reshape((1, input_dim))(inputs)\n",
    "    \n",
    "    # Stack Transformer Blocks\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerEncoder(num_heads, ff_dim, input_dim, dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Output layer for classification\n",
    "    outputs = layers.Dense(output_dim, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6f4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = x_train.shape[1]  # Number of features\n",
    "output_dim = len(y_train.unique())  # Number of classes for classification\n",
    "num_heads = 8\n",
    "ff_dim = 64\n",
    "num_transformer_blocks = 4\n",
    "dropout_rate = 0.1\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae5680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_transformer_model(input_dim, output_dim, num_heads, ff_dim, num_transformer_blocks, dropout_rate)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d06f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "82/82 [==============================] - 5s 11ms/step - loss: 1.5831 - accuracy: 0.4139 - val_loss: 1.2961 - val_accuracy: 0.4947\n",
      "Epoch 2/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.2624 - accuracy: 0.5295 - val_loss: 1.1704 - val_accuracy: 0.5662\n",
      "Epoch 3/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 1.1465 - accuracy: 0.5696 - val_loss: 1.1201 - val_accuracy: 0.5903\n",
      "Epoch 4/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 1.0621 - accuracy: 0.6071 - val_loss: 1.1091 - val_accuracy: 0.5977\n",
      "Epoch 5/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 1.0265 - accuracy: 0.6232 - val_loss: 0.9779 - val_accuracy: 0.6345\n",
      "Epoch 6/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.9741 - accuracy: 0.6484 - val_loss: 0.9803 - val_accuracy: 0.6481\n",
      "Epoch 7/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.9408 - accuracy: 0.6511 - val_loss: 0.9504 - val_accuracy: 0.6807\n",
      "Epoch 8/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.9080 - accuracy: 0.6683 - val_loss: 0.9739 - val_accuracy: 0.6555\n",
      "Epoch 9/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.8758 - accuracy: 0.6729 - val_loss: 0.9770 - val_accuracy: 0.6534\n",
      "Epoch 10/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8533 - accuracy: 0.6821 - val_loss: 0.8833 - val_accuracy: 0.6996\n",
      "Epoch 11/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8343 - accuracy: 0.6951 - val_loss: 0.9820 - val_accuracy: 0.6649\n",
      "Epoch 12/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.8368 - accuracy: 0.6959 - val_loss: 0.9342 - val_accuracy: 0.6597\n",
      "Epoch 13/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.7913 - accuracy: 0.7093 - val_loss: 0.8849 - val_accuracy: 0.6786\n",
      "Epoch 14/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.7573 - accuracy: 0.7253 - val_loss: 0.8891 - val_accuracy: 0.6901\n",
      "Epoch 15/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.7539 - accuracy: 0.7368 - val_loss: 0.8526 - val_accuracy: 0.7038\n",
      "Epoch 16/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.7339 - accuracy: 0.7395 - val_loss: 0.7958 - val_accuracy: 0.7122\n",
      "Epoch 17/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.7105 - accuracy: 0.7433 - val_loss: 0.8437 - val_accuracy: 0.7080\n",
      "Epoch 18/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.7059 - accuracy: 0.7479 - val_loss: 0.8078 - val_accuracy: 0.7206\n",
      "Epoch 19/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6497 - accuracy: 0.7701 - val_loss: 0.8566 - val_accuracy: 0.7143\n",
      "Epoch 20/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6489 - accuracy: 0.7686 - val_loss: 0.7896 - val_accuracy: 0.7395\n",
      "Epoch 21/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.7663 - val_loss: 0.7435 - val_accuracy: 0.7290\n",
      "Epoch 22/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6218 - accuracy: 0.7720 - val_loss: 0.8253 - val_accuracy: 0.7143\n",
      "Epoch 23/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6119 - accuracy: 0.7808 - val_loss: 0.7132 - val_accuracy: 0.7468\n",
      "Epoch 24/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7999 - val_loss: 0.7357 - val_accuracy: 0.7616\n",
      "Epoch 25/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.7984 - val_loss: 0.7872 - val_accuracy: 0.7426\n",
      "Epoch 26/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.7819 - val_loss: 0.7872 - val_accuracy: 0.7290\n",
      "Epoch 27/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5640 - accuracy: 0.7957 - val_loss: 0.7092 - val_accuracy: 0.7700\n",
      "Epoch 28/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.8003 - val_loss: 0.7152 - val_accuracy: 0.7511\n",
      "Epoch 29/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.8122 - val_loss: 0.7633 - val_accuracy: 0.7311\n",
      "Epoch 30/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.8122 - val_loss: 0.7375 - val_accuracy: 0.7479\n",
      "Epoch 31/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.8041 - val_loss: 0.7311 - val_accuracy: 0.7605\n",
      "Epoch 32/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.8213 - val_loss: 0.7847 - val_accuracy: 0.7363\n",
      "Epoch 33/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.8049 - val_loss: 0.7715 - val_accuracy: 0.7416\n",
      "Epoch 34/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.8087 - val_loss: 0.7644 - val_accuracy: 0.7447\n",
      "Epoch 35/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.8275 - val_loss: 0.7462 - val_accuracy: 0.7511\n",
      "Epoch 36/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.4864 - accuracy: 0.8194 - val_loss: 0.7210 - val_accuracy: 0.7668\n",
      "Epoch 37/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.8294 - val_loss: 0.7440 - val_accuracy: 0.7447\n",
      "Epoch 38/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8336 - val_loss: 0.7244 - val_accuracy: 0.7574\n",
      "Epoch 39/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8366 - val_loss: 0.7325 - val_accuracy: 0.7563\n",
      "Epoch 40/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.8347 - val_loss: 0.7420 - val_accuracy: 0.7532\n",
      "Epoch 41/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8290 - val_loss: 0.7378 - val_accuracy: 0.7595\n",
      "Epoch 42/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8493 - val_loss: 0.7119 - val_accuracy: 0.7700\n",
      "Epoch 43/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8474 - val_loss: 0.8405 - val_accuracy: 0.7258\n",
      "Epoch 44/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.8294 - val_loss: 0.7785 - val_accuracy: 0.7542\n",
      "Epoch 45/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8592 - val_loss: 0.7201 - val_accuracy: 0.7574\n",
      "Epoch 46/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8623 - val_loss: 0.7406 - val_accuracy: 0.7721\n",
      "Epoch 47/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.8405 - val_loss: 0.7055 - val_accuracy: 0.7668\n",
      "Epoch 48/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8627 - val_loss: 0.7904 - val_accuracy: 0.7647\n",
      "Epoch 49/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8726 - val_loss: 0.8230 - val_accuracy: 0.7605\n",
      "Epoch 50/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8562 - val_loss: 0.7264 - val_accuracy: 0.7773\n",
      "Epoch 51/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8634 - val_loss: 0.7198 - val_accuracy: 0.7784\n",
      "Epoch 52/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8615 - val_loss: 0.7230 - val_accuracy: 0.7847\n",
      "Epoch 53/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.8833 - val_loss: 0.6855 - val_accuracy: 0.7941\n",
      "Epoch 54/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3183 - accuracy: 0.8783 - val_loss: 0.7614 - val_accuracy: 0.7689\n",
      "Epoch 55/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3555 - accuracy: 0.8673 - val_loss: 0.7791 - val_accuracy: 0.7658\n",
      "Epoch 56/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8615 - val_loss: 0.7503 - val_accuracy: 0.7668\n",
      "Epoch 57/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3404 - accuracy: 0.8726 - val_loss: 0.7503 - val_accuracy: 0.7731\n",
      "Epoch 58/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8730 - val_loss: 0.7502 - val_accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8803 - val_loss: 0.7581 - val_accuracy: 0.7847\n",
      "Epoch 60/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3113 - accuracy: 0.8879 - val_loss: 0.7267 - val_accuracy: 0.7763\n",
      "Epoch 61/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8772 - val_loss: 0.6724 - val_accuracy: 0.7962\n",
      "Epoch 62/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3233 - accuracy: 0.8810 - val_loss: 0.7954 - val_accuracy: 0.7710\n",
      "Epoch 63/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3111 - accuracy: 0.8868 - val_loss: 0.7896 - val_accuracy: 0.7815\n",
      "Epoch 64/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2878 - accuracy: 0.8967 - val_loss: 0.8653 - val_accuracy: 0.7731\n",
      "Epoch 65/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.2776 - accuracy: 0.9032 - val_loss: 0.7773 - val_accuracy: 0.7763\n",
      "Epoch 66/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.3217 - accuracy: 0.8914 - val_loss: 0.7574 - val_accuracy: 0.7794\n",
      "Epoch 67/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.3047 - accuracy: 0.8936 - val_loss: 0.7413 - val_accuracy: 0.7836\n",
      "Epoch 68/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2977 - accuracy: 0.8887 - val_loss: 0.7415 - val_accuracy: 0.7868\n",
      "Epoch 69/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.3049 - accuracy: 0.8898 - val_loss: 0.8360 - val_accuracy: 0.7668\n",
      "Epoch 70/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3014 - accuracy: 0.8914 - val_loss: 0.7695 - val_accuracy: 0.7700\n",
      "Epoch 71/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.2849 - accuracy: 0.8971 - val_loss: 0.8507 - val_accuracy: 0.7700\n",
      "Epoch 72/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2983 - accuracy: 0.8967 - val_loss: 0.7050 - val_accuracy: 0.8015\n",
      "Epoch 73/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2851 - accuracy: 0.8975 - val_loss: 0.7443 - val_accuracy: 0.8078\n",
      "Epoch 74/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2830 - accuracy: 0.8952 - val_loss: 0.7835 - val_accuracy: 0.7920\n",
      "Epoch 75/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.2894 - accuracy: 0.8914 - val_loss: 0.7904 - val_accuracy: 0.7878\n",
      "Epoch 76/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2620 - accuracy: 0.9032 - val_loss: 0.7488 - val_accuracy: 0.7899\n",
      "Epoch 77/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2614 - accuracy: 0.9002 - val_loss: 0.8006 - val_accuracy: 0.7910\n",
      "Epoch 78/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2709 - accuracy: 0.9032 - val_loss: 0.7992 - val_accuracy: 0.7910\n",
      "Epoch 79/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2683 - accuracy: 0.9009 - val_loss: 0.8260 - val_accuracy: 0.7689\n",
      "Epoch 80/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2578 - accuracy: 0.9005 - val_loss: 0.8139 - val_accuracy: 0.7752\n",
      "Epoch 81/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2416 - accuracy: 0.9132 - val_loss: 0.7685 - val_accuracy: 0.7952\n",
      "Epoch 82/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2382 - accuracy: 0.9135 - val_loss: 0.8285 - val_accuracy: 0.7868\n",
      "Epoch 83/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2289 - accuracy: 0.9124 - val_loss: 0.8135 - val_accuracy: 0.7815\n",
      "Epoch 84/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2710 - accuracy: 0.9005 - val_loss: 0.8200 - val_accuracy: 0.7910\n",
      "Epoch 85/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2359 - accuracy: 0.9105 - val_loss: 0.7980 - val_accuracy: 0.7920\n",
      "Epoch 86/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.2732 - accuracy: 0.9009 - val_loss: 0.8445 - val_accuracy: 0.7836\n",
      "Epoch 87/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.2398 - accuracy: 0.9158 - val_loss: 0.7592 - val_accuracy: 0.8025\n",
      "Epoch 88/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2092 - accuracy: 0.9223 - val_loss: 0.8013 - val_accuracy: 0.7889\n",
      "Epoch 89/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2396 - accuracy: 0.9086 - val_loss: 0.8087 - val_accuracy: 0.7962\n",
      "Epoch 90/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.9109 - val_loss: 0.8944 - val_accuracy: 0.7700\n",
      "Epoch 91/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.2552 - accuracy: 0.9055 - val_loss: 0.8437 - val_accuracy: 0.7710\n",
      "Epoch 92/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2273 - accuracy: 0.9197 - val_loss: 0.8141 - val_accuracy: 0.7847\n",
      "Epoch 93/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.1992 - accuracy: 0.9254 - val_loss: 0.8178 - val_accuracy: 0.7847\n",
      "Epoch 94/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2148 - accuracy: 0.9189 - val_loss: 0.8248 - val_accuracy: 0.7994\n",
      "Epoch 95/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9181 - val_loss: 0.8603 - val_accuracy: 0.7784\n",
      "Epoch 96/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2449 - accuracy: 0.9093 - val_loss: 0.8633 - val_accuracy: 0.7784\n",
      "Epoch 97/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2191 - accuracy: 0.9128 - val_loss: 0.9079 - val_accuracy: 0.7815\n",
      "Epoch 98/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2159 - accuracy: 0.9200 - val_loss: 0.8682 - val_accuracy: 0.7836\n",
      "Epoch 99/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.1964 - accuracy: 0.9334 - val_loss: 0.8117 - val_accuracy: 0.7920\n",
      "Epoch 100/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.1800 - accuracy: 0.9327 - val_loss: 0.8658 - val_accuracy: 0.7805\n",
      "Epoch 101/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2352 - accuracy: 0.9178 - val_loss: 0.8069 - val_accuracy: 0.7941\n",
      "Epoch 102/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2099 - accuracy: 0.9262 - val_loss: 0.7784 - val_accuracy: 0.8004\n",
      "Epoch 103/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.1858 - accuracy: 0.9331 - val_loss: 0.7797 - val_accuracy: 0.7941\n",
      "Epoch 104/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.9388 - val_loss: 0.7793 - val_accuracy: 0.8099\n",
      "Epoch 105/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2181 - accuracy: 0.9227 - val_loss: 0.8316 - val_accuracy: 0.8120\n",
      "Epoch 106/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.9403 - val_loss: 0.8817 - val_accuracy: 0.7910\n",
      "Epoch 107/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.9334 - val_loss: 0.9330 - val_accuracy: 0.7721\n",
      "Epoch 108/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.2164 - accuracy: 0.9216 - val_loss: 0.8466 - val_accuracy: 0.7973\n",
      "Epoch 109/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2324 - accuracy: 0.9170 - val_loss: 0.9063 - val_accuracy: 0.7920\n",
      "Epoch 110/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1998 - accuracy: 0.9300 - val_loss: 0.8827 - val_accuracy: 0.7794\n",
      "Epoch 111/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9262 - val_loss: 0.8079 - val_accuracy: 0.7952\n",
      "Epoch 112/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1806 - accuracy: 0.9319 - val_loss: 0.8666 - val_accuracy: 0.7931\n",
      "Epoch 113/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.9208 - val_loss: 0.8017 - val_accuracy: 0.7952\n",
      "Epoch 114/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1864 - accuracy: 0.9315 - val_loss: 0.8152 - val_accuracy: 0.8120\n",
      "Epoch 115/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2037 - accuracy: 0.9292 - val_loss: 0.8430 - val_accuracy: 0.7952\n",
      "Epoch 116/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1721 - accuracy: 0.9376 - val_loss: 0.7704 - val_accuracy: 0.8025\n",
      "Epoch 117/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1661 - accuracy: 0.9373 - val_loss: 0.8287 - val_accuracy: 0.7931\n",
      "Epoch 118/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1917 - accuracy: 0.9285 - val_loss: 0.8077 - val_accuracy: 0.7994\n",
      "Epoch 119/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1760 - accuracy: 0.9365 - val_loss: 0.8125 - val_accuracy: 0.7910\n",
      "Epoch 120/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1646 - accuracy: 0.9472 - val_loss: 0.8111 - val_accuracy: 0.8162\n",
      "Epoch 121/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.9411 - val_loss: 0.8470 - val_accuracy: 0.8078\n",
      "Epoch 122/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.2113 - accuracy: 0.9269 - val_loss: 0.8268 - val_accuracy: 0.8004\n",
      "Epoch 123/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1747 - accuracy: 0.9411 - val_loss: 0.8840 - val_accuracy: 0.7952\n",
      "Epoch 124/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1544 - accuracy: 0.9441 - val_loss: 0.8784 - val_accuracy: 0.7836\n",
      "Epoch 125/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1863 - accuracy: 0.9353 - val_loss: 0.8898 - val_accuracy: 0.7910\n",
      "Epoch 126/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9484 - val_loss: 0.8625 - val_accuracy: 0.7899\n",
      "Epoch 127/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1803 - accuracy: 0.9342 - val_loss: 0.8720 - val_accuracy: 0.7931\n",
      "Epoch 128/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1788 - accuracy: 0.9357 - val_loss: 0.8595 - val_accuracy: 0.7952\n",
      "Epoch 129/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9430 - val_loss: 0.9914 - val_accuracy: 0.7700\n",
      "Epoch 130/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1992 - accuracy: 0.9338 - val_loss: 0.8634 - val_accuracy: 0.8004\n",
      "Epoch 131/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1605 - accuracy: 0.9453 - val_loss: 0.8512 - val_accuracy: 0.8036\n",
      "Epoch 132/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1702 - accuracy: 0.9331 - val_loss: 0.8183 - val_accuracy: 0.7994\n",
      "Epoch 133/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 0.9369 - val_loss: 0.8465 - val_accuracy: 0.7847\n",
      "Epoch 134/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.1793 - accuracy: 0.9361 - val_loss: 0.9125 - val_accuracy: 0.7941\n",
      "Epoch 135/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1981 - accuracy: 0.9258 - val_loss: 0.9137 - val_accuracy: 0.7826\n",
      "Epoch 136/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1779 - accuracy: 0.9334 - val_loss: 0.8595 - val_accuracy: 0.8036\n",
      "Epoch 137/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.9491 - val_loss: 0.9048 - val_accuracy: 0.7899\n",
      "Epoch 138/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.9449 - val_loss: 0.9570 - val_accuracy: 0.7826\n",
      "Epoch 139/400\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.1689 - accuracy: 0.9365 - val_loss: 0.8422 - val_accuracy: 0.8004\n",
      "Epoch 140/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9407 - val_loss: 0.9779 - val_accuracy: 0.7857\n",
      "Epoch 141/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1409 - accuracy: 0.9491 - val_loss: 0.8940 - val_accuracy: 0.7941\n",
      "Epoch 142/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9552 - val_loss: 0.9449 - val_accuracy: 0.7889\n",
      "Epoch 143/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9537 - val_loss: 0.9070 - val_accuracy: 0.7962\n",
      "Epoch 144/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1620 - accuracy: 0.9369 - val_loss: 0.8434 - val_accuracy: 0.8057\n",
      "Epoch 145/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9403 - val_loss: 0.9339 - val_accuracy: 0.7899\n",
      "Epoch 146/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.9461 - val_loss: 0.8655 - val_accuracy: 0.8078\n",
      "Epoch 147/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.9484 - val_loss: 0.9136 - val_accuracy: 0.8015\n",
      "Epoch 148/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9445 - val_loss: 0.9159 - val_accuracy: 0.8057\n",
      "Epoch 149/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9396 - val_loss: 0.9405 - val_accuracy: 0.7952\n",
      "Epoch 150/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.9472 - val_loss: 1.0036 - val_accuracy: 0.7731\n",
      "Epoch 151/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9480 - val_loss: 0.9563 - val_accuracy: 0.7794\n",
      "Epoch 152/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1392 - accuracy: 0.9510 - val_loss: 0.9448 - val_accuracy: 0.7847\n",
      "Epoch 153/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9518 - val_loss: 1.0397 - val_accuracy: 0.7868\n",
      "Epoch 154/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1778 - accuracy: 0.9361 - val_loss: 0.9576 - val_accuracy: 0.7847\n",
      "Epoch 155/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9346 - val_loss: 1.0116 - val_accuracy: 0.7794\n",
      "Epoch 156/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9461 - val_loss: 0.9100 - val_accuracy: 0.7847\n",
      "Epoch 157/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1626 - accuracy: 0.9380 - val_loss: 1.0179 - val_accuracy: 0.7721\n",
      "Epoch 158/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.9407 - val_loss: 0.8910 - val_accuracy: 0.8015\n",
      "Epoch 159/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1535 - accuracy: 0.9491 - val_loss: 0.9183 - val_accuracy: 0.7994\n",
      "Epoch 160/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.9365 - val_loss: 1.0394 - val_accuracy: 0.7889\n",
      "Epoch 161/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1441 - accuracy: 0.9491 - val_loss: 0.8954 - val_accuracy: 0.7910\n",
      "Epoch 162/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1468 - accuracy: 0.9495 - val_loss: 0.9668 - val_accuracy: 0.7826\n",
      "Epoch 163/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9495 - val_loss: 0.9297 - val_accuracy: 0.7878\n",
      "Epoch 164/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9568 - val_loss: 0.9194 - val_accuracy: 0.7899\n",
      "Epoch 165/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9625 - val_loss: 0.9218 - val_accuracy: 0.8025\n",
      "Epoch 166/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.9522 - val_loss: 1.0112 - val_accuracy: 0.7931\n",
      "Epoch 167/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9461 - val_loss: 0.9072 - val_accuracy: 0.7983\n",
      "Epoch 168/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1544 - accuracy: 0.9461 - val_loss: 0.9988 - val_accuracy: 0.7815\n",
      "Epoch 169/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9396 - val_loss: 0.9149 - val_accuracy: 0.7973\n",
      "Epoch 170/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1539 - accuracy: 0.9388 - val_loss: 0.9537 - val_accuracy: 0.7920\n",
      "Epoch 171/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9510 - val_loss: 0.9718 - val_accuracy: 0.7847\n",
      "Epoch 172/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1801 - accuracy: 0.9334 - val_loss: 0.9739 - val_accuracy: 0.7763\n",
      "Epoch 173/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9484 - val_loss: 0.9548 - val_accuracy: 0.7815\n",
      "Epoch 174/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9549 - val_loss: 0.9201 - val_accuracy: 0.7931\n",
      "Epoch 175/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1303 - accuracy: 0.9526 - val_loss: 0.9412 - val_accuracy: 0.7889\n",
      "Epoch 176/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9575 - val_loss: 0.9432 - val_accuracy: 0.8004\n",
      "Epoch 177/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9610 - val_loss: 0.9427 - val_accuracy: 0.7952\n",
      "Epoch 178/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1845 - accuracy: 0.9331 - val_loss: 0.9020 - val_accuracy: 0.8025\n",
      "Epoch 179/400\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.1517 - accuracy: 0.9464 - val_loss: 0.9334 - val_accuracy: 0.7941\n",
      "Epoch 180/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9568 - val_loss: 0.8973 - val_accuracy: 0.8015\n",
      "Epoch 181/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.9598 - val_loss: 0.9100 - val_accuracy: 0.8057\n",
      "Epoch 182/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1785 - accuracy: 0.9426 - val_loss: 0.8561 - val_accuracy: 0.8120\n",
      "Epoch 183/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9518 - val_loss: 0.9426 - val_accuracy: 0.7962\n",
      "Epoch 184/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9675 - val_loss: 0.9093 - val_accuracy: 0.7983\n",
      "Epoch 185/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9526 - val_loss: 0.9726 - val_accuracy: 0.7836\n",
      "Epoch 186/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1480 - accuracy: 0.9468 - val_loss: 1.0009 - val_accuracy: 0.8015\n",
      "Epoch 187/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9564 - val_loss: 1.0113 - val_accuracy: 0.7868\n",
      "Epoch 188/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1494 - accuracy: 0.9507 - val_loss: 0.9051 - val_accuracy: 0.7889\n",
      "Epoch 189/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9564 - val_loss: 0.9287 - val_accuracy: 0.7941\n",
      "Epoch 190/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9510 - val_loss: 0.9465 - val_accuracy: 0.7973\n",
      "Epoch 191/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1127 - accuracy: 0.9621 - val_loss: 0.9723 - val_accuracy: 0.8088\n",
      "Epoch 192/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.9579 - val_loss: 0.9195 - val_accuracy: 0.7920\n",
      "Epoch 193/400\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.9583 - val_loss: 0.9071 - val_accuracy: 0.8025\n",
      "Epoch 194/400\n",
      "31/82 [==========>...................] - ETA: 0s - loss: 0.1295 - accuracy: 0.9526"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7295ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97808ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b427c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e787f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "if len(y_test.shape) == 1 or y_test.shape[1] == 1:\n",
    "    y_true = y_test  \n",
    "else:\n",
    "    y_true = np.argmax(y_test, axis=1)  \n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "class_report = classification_report(y_true, y_pred_classes, target_names=[str(i) for i in range(len(np.unique(y_true)))])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa16eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
