{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9528f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f8b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('ML_Data_48.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3723713",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Z_jerk_mean', 'X_jerk_mean', 'total_jerk_mean', 'Y_jerk_mean','X_jerk_mean','X_jerk_min', 'X_min', 'timestamp_range', 'Y_mean', 'X_mean', 'X_max','Z_mean', 'X_jerk_max', 'X_jerk_range', 'X_range'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8298dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'X_rms', 'X_std', 'Y_min', 'Y_max', 'Y_range', 'Y_rms',\n",
       "       'Y_std', 'Z_min', 'Z_max', 'Z_range', 'Z_rms', 'Z_std', 'X_jerk_rms',\n",
       "       'X_jerk_std', 'Y_jerk_min', 'Y_jerk_max', 'Y_jerk_range', 'Y_jerk_rms',\n",
       "       'Y_jerk_std', 'Z_jerk_min', 'Z_jerk_max', 'Z_jerk_range', 'Z_jerk_rms',\n",
       "       'Z_jerk_std', 'total_jerk_min', 'total_jerk_max', 'total_jerk_range',\n",
       "       'total_jerk_rms', 'total_jerk_std', 'SMA', 'X_entropy', 'Y_entropy',\n",
       "       'Z_entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4f6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6bf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['label'], axis=1)\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9484ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=StandardScaler()\n",
    "x=scale.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e292cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2614, 33), (1121, 33))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_t, y_train, y_t= train_test_split(x,y,test_size=0.3, random_state=42)\n",
    "x_train.shape, x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659799ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((952, 33), (169, 33))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, x_test, y_val, y_test= train_test_split(x_t, y_t, test_size=0.15, random_state=42)\n",
    "x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f47d9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 20:51:34.622321: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-25 20:51:34.623642: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-25 20:51:34.645403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-25 20:51:34.645426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-25 20:51:34.645441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-25 20:51:34.649572: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-25 20:51:34.650111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 20:51:35.199252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc28cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7199b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(0.7),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ee6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.01\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,      # Starting learning rate\n",
    "    decay_steps=1000,         # How often to decay the learning rate\n",
    "    decay_rate=0.96,            # The decay rate\n",
    "    staircase=True              # Apply decay in discrete steps\n",
    ")\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=70, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7621c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=SGD(learning_rate=lr_schedule, \n",
    "#                             momentum=0.97, \n",
    "#                             nesterov=True),  # Enable Nesterov momentum\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b99326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                                epochs=500,\n",
    "                                batch_size=64,\n",
    "                                validation_data= (x_val, y_val),\n",
    "                                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89b654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "if len(y_test.shape) == 1 or y_test.shape[1] == 1:\n",
    "    y_true = y_test  \n",
    "else:\n",
    "    y_true = np.argmax(y_test, axis=1)  \n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "class_report = classification_report(y_true, y_pred_classes, target_names=[str(i) for i in range(len(np.unique(y_true)))])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
